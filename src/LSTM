import numpy as np
import tensorflow as tf
import os
import pandas as pd
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from sklearn.preprocessing import StandardScaler

data_path = "data"
all_data = []
all_labels = []
file_count = 0

for folder_name in os.listdir(data_path):
    folder_path = os.path.join(data_path, folder_name)

    # Check if it's a folder
    if os.path.isdir(folder_path):
        print(f"Loading data from: {folder_path}")

        # Loop through each file in the folder
        for file_name in os.listdir(folder_path):
            file_path = os.path.join(folder_path, file_name)

            # Check if the file is a CSV
            if file_name.endswith(".csv"):
                df = pd.read_csv(file_path)

                labels = df.iloc[:, -1].values  # Extract labels
                data = df.iloc[:, :-1].values  # Extract features

                # Store data
                all_data.append(data)
                all_labels.append(labels)


                file_count += 1

print(f"Total files loaded: {file_count}")


data = np.vstack(all_data)  # Stack arrays vertically
labels = np.hstack(all_labels)

# Normalize the data
scaler = StandardScaler()
data = scaler.fit_transform(data)

# Reshape data for LSTM input (samples, time steps, features)
data = data.reshape((data.shape[0], 1, data.shape[1]))

# Split data into training and testing sets
train_size = int(len(data) * 0.8)
X_train, X_test = data[:train_size], data[train_size:]
y_train, y_test = labels[:train_size], labels[train_size:]

# See the shape
print(f"Final dataset shape: {data.shape}")
print(f"Training set: {X_train.shape}, {y_train.shape}")
print(f"Testing set: {X_test.shape}, {y_test.shape}")


# Build the LSTM model
model = Sequential()
model.add(LSTM(64, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])))
model.add(Dense(1, activation='sigmoid'))

# Compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}, Test Accuracy: {accuracy}")