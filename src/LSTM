import os
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Masking
from tensorflow.keras.preprocessing.sequence import pad_sequences

# Path to the main data folder
data_root = "data"

# Lists to store sequences and labels
sequences = []
labels = []
file_count = 0  

# Maximum sequence length tracking
max_seq_length = 0

# Loop through each folder (class label)
for folder_name in os.listdir(data_root):
    folder_path = os.path.join(data_root, folder_name)

    if os.path.isdir(folder_path):
        print(f"Loading data from: {folder_path}")

        # Loop through each CSV file
        for file_name in os.listdir(folder_path):
            file_path = os.path.join(folder_path, file_name)

            if file_name.endswith(".csv"):
                df = pd.read_csv(file_path)

                # Convert all data to numeric
                df = df.apply(pd.to_numeric, errors='coerce').fillna(0)
                df = df.iloc[:, :-1]

                # Extract all features
                data = df.values  # Shape: (time_steps, features)

                # Track max sequence length
                max_seq_length = max(max_seq_length, data.shape[0])

                # Store sequence and label
                sequences.append(data)
                labels.append(folder_name)
                file_count += 1  

print(f"Total files loaded: {file_count}")

# Convert labels to numerical format
label_encoder = LabelEncoder()
encoded_labels = label_encoder.fit_transform(labels)
encoded_labels = to_categorical(encoded_labels)

# Padding sequences to ensure uniform shape
sequences = pad_sequences(sequences, maxlen=max_seq_length, dtype='float32', padding='post', truncating='post')

print(f"Final dataset shape: {sequences.shape}")  # (num_samples, max_time_steps, num_features)
print(f"Labels shape: {encoded_labels.shape}")  # (num_samples, num_classes)

# Split data into training and testing sets
train_size = int(len(sequences) * 0.8)
X_train, X_test = sequences[:train_size], sequences[train_size:]
y_train, y_test = encoded_labels[:train_size], encoded_labels[train_size:]

print(f"Training set: {X_train.shape}, {y_train.shape}")
print(f"Testing set: {X_test.shape}, {y_test.shape}")

# Define the LSTM model
model = Sequential()
model.add(Masking(mask_value=0.0, input_shape=(X_train.shape[1], X_train.shape[2])))  # Masking padded values
model.add(LSTM(64, activation='relu'))
model.add(Dense(y_train.shape[1], activation='softmax'))

# Compile the model
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# Train the model
model.fit(X_train, y_train, epochs=50, batch_size=8, validation_data=(X_test, y_test))

# Evaluate the model
loss, accuracy = model.evaluate(X_test, y_test)
print(f"Test Loss: {loss}, Test Accuracy: {accuracy}")
